{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4d5c8c0",
   "metadata": {},
   "source": [
    "# Flight Delay Prediction: Data Generation, Wrangling, and EDA Workflow\n",
    "\n",
    "This notebook provides a comprehensive workflow for the Flight Delay Prediction project, covering:\n",
    "1. **Synthetic Data Generation**: Creating realistic flight and weather datasets.\n",
    "2. **Data Wrangling and Cleaning**: Processing raw data, handling missing values, and feature engineering.\n",
    "3. **Exploratory Data Analysis (EDA)**: Visualizing data to uncover patterns, trends, and insights related to flight delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb93d04",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Generation\n",
    "\n",
    "This section covers the generation of synthetic airline on-time performance data and weather data. Due to limitations in accessing real-time APIs for historical data in this environment, we use synthetic data that mimics the structure and characteristics of real-world datasets from sources like the Bureau of Transportation Statistics (BTS) and the National Oceanic and Atmospheric Administration (NOAA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2064fcf",
   "metadata": {},
   "source": [
    "### 1.1 Setup and Imports for Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824435d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import glob\n",
    "\n",
    "# Ensure necessary directories exist\n",
    "base_dir = '.'\n",
    "os.makedirs(os.path.join(base_dir, 'data/raw/airline'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'data/raw/weather'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'data/processed'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'visualizations/general'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'visualizations/seasonal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'visualizations/network'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'results'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c00a9",
   "metadata": {},
   "source": [
    "### 1.2 Helper Functions for Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Acquisition Script for Flight Delay Analysis Project (Modified)\n",
    "This script downloads airline on-time performance data from the Bureau of Transportation Statistics (BTS)\n",
    "and weather data from the National Oceanic and Atmospheric Administration (NOAA).\n",
    "Modified to use synthetic data due to API access limitations.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Create data directories if they don't exist\n",
    "os.makedirs('data/raw/airline', exist_ok=True)\n",
    "os.makedirs('data/raw/weather', exist_ok=True)\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "def generate_synthetic_airline_data(year, month, airports_df, airlines_df):\n",
    "    \"\"\"\n",
    "    Generate synthetic airline on-time performance data for a specific year and month.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    year : int\n",
    "        Year of data to generate\n",
    "    month : int\n",
    "        Month of data to generate\n",
    "    airports_df : pandas.DataFrame\n",
    "        DataFrame containing airport information\n",
    "    airlines_df : pandas.DataFrame\n",
    "        DataFrame containing airline information\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the synthetic airline data\n",
    "    \"\"\"\n",
    "    print(f\"Generating synthetic airline data for {year}-{month:02d}...\")\n",
    "    \n",
    "    # Get airport codes\n",
    "    airport_codes = airports_df['IATA'].tolist()\n",
    "    \n",
    "    # Get airline codes\n",
    "    airline_codes = airlines_df['Code'].tolist()\n",
    "    \n",
    "    # Create date range for the month\n",
    "    start_date = datetime(year, month, 1)\n",
    "    if month == 12:\n",
    "        end_date = datetime(year + 1, 1, 1) - timedelta(days=1)\n",
    "    else:\n",
    "        end_date = datetime(year, month + 1, 1) - timedelta(days=1)\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    \n",
    "    # Generate synthetic flight data\n",
    "    all_flights = []\n",
    "    \n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(year * 100 + month)\n",
    "    \n",
    "    # Generate approximately 100 flights per day\n",
    "    for date in date_range:\n",
    "        for _ in range(100):\n",
    "            # Randomly select origin and destination airports (ensure they're different)\n",
    "            origin_idx = np.random.randint(0, len(airport_codes))\n",
    "            dest_idx = (origin_idx + np.random.randint(1, len(airport_codes))) % len(airport_codes)\n",
    "            \n",
    "            origin = airport_codes[origin_idx]\n",
    "            dest = airport_codes[dest_idx]\n",
    "            \n",
    "            # Randomly select airline\n",
    "            airline = airline_codes[np.random.randint(0, len(airline_codes))]\n",
    "            \n",
    "            # Generate scheduled departure and arrival times\n",
    "            dep_hour = np.random.randint(6, 22)  # Between 6 AM and 10 PM\n",
    "            dep_minute = np.random.randint(0, 60)\n",
    "            scheduled_dep_time = f\"{dep_hour:02d}{dep_minute:02d}\"\n",
    "            \n",
    "            flight_duration = np.random.normal(120, 30)  # Mean 2 hours, std 30 minutes\n",
    "            flight_duration = max(30, flight_duration)  # Minimum 30 minutes\n",
    "            \n",
    "            arr_datetime = date + timedelta(hours=dep_hour, minutes=dep_minute) + timedelta(minutes=flight_duration)\n",
    "            scheduled_arr_time = f\"{arr_datetime.hour:02d}{arr_datetime.minute:02d}\"\n",
    "            \n",
    "            # Generate delay information\n",
    "            dep_delay = max(0, np.random.exponential(15) if np.random.random() < 0.3 else 0)\n",
    "            arr_delay = dep_delay + np.random.normal(0, 10)\n",
    "            \n",
    "            # Determine if flight was cancelled or diverted\n",
    "            cancelled = 1 if np.random.random() < 0.02 else 0  # 2% cancellation rate\n",
    "            diverted = 1 if not cancelled and np.random.random() < 0.01 else 0  # 1% diversion rate\n",
    "            \n",
    "            # Determine delay causes (only if delayed)\n",
    "            if dep_delay > 15:\n",
    "                carrier_delay = np.random.exponential(20) if np.random.random() < 0.3 else 0\n",
    "                weather_delay = np.random.exponential(30) if np.random.random() < 0.2 else 0\n",
    "                nas_delay = np.random.exponential(15) if np.random.random() < 0.4 else 0\n",
    "                security_delay = np.random.exponential(10) if np.random.random() < 0.05 else 0\n",
    "                late_aircraft_delay = np.random.exponential(25) if np.random.random() < 0.3 else 0\n",
    "            else:\n",
    "                carrier_delay = weather_delay = nas_delay = security_delay = late_aircraft_delay = 0\n",
    "            \n",
    "            # Create flight record\n",
    "            flight = {\n",
    "                'FlightDate': date.strftime('%Y-%m-%d'),\n",
    "                'Reporting_Airline': airline,\n",
    "                'Origin': origin,\n",
    "                'Dest': dest,\n",
    "                'CRSDepTime': scheduled_dep_time,\n",
    "                'CRSArrTime': scheduled_arr_time,\n",
    "                'DepDelay': round(dep_delay, 1),\n",
    "                'ArrDelay': round(arr_delay, 1),\n",
    "                'Cancelled': cancelled,\n",
    "                'Diverted': diverted,\n",
    "                'CarrierDelay': round(carrier_delay) if not cancelled and not diverted else None,\n",
    "                'WeatherDelay': round(weather_delay) if not cancelled and not diverted else None,\n",
    "                'NASDelay': round(nas_delay) if not cancelled and not diverted else None,\n",
    "                'SecurityDelay': round(security_delay) if not cancelled and not diverted else None,\n",
    "                'LateAircraftDelay': round(late_aircraft_delay) if not cancelled and not diverted else None,\n",
    "                'Distance': round(np.random.normal(800, 300))  # Mean 800 miles, std 300 miles\n",
    "            }\n",
    "            \n",
    "            all_flights.append(flight)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_flights)\n",
    "    \n",
    "    # Save raw data\n",
    "    output_file = f\"data/raw/airline/airline_data_{year}_{month:02d}.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved synthetic airline data to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_synthetic_weather_data(station_ids, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generate synthetic weather data for specific weather stations and date range.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    station_ids : list\n",
    "        List of NOAA weather station IDs (typically near major airports)\n",
    "    start_date : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end_date : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the synthetic weather data\n",
    "    \"\"\"\n",
    "    print(f\"Generating synthetic weather data from {start_date} to {end_date}...\")\n",
    "    \n",
    "    # Create a date range\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    \n",
    "    # Create simulated weather data for each station\n",
    "    all_weather_data = []\n",
    "    \n",
    "    for station_id in station_ids:\n",
    "        # Use part of station ID as seed for reproducibility\n",
    "        np.random.seed(int(station_id[-3:]))\n",
    "        \n",
    "        for date in date_range:\n",
    "            # Determine season for more realistic weather patterns\n",
    "            month = date.month\n",
    "            if month in [12, 1, 2]:\n",
    "                season = 'winter'\n",
    "            elif month in [3, 4, 5]:\n",
    "                season = 'spring'\n",
    "            elif month in [6, 7, 8]:\n",
    "                season = 'summer'\n",
    "            else:\n",
    "                season = 'fall'\n",
    "            \n",
    "            # Adjust temperature based on season\n",
    "            if season == 'winter':\n",
    "                temp_mean = 35\n",
    "                temp_std = 15\n",
    "            elif season == 'spring':\n",
    "                temp_mean = 60\n",
    "                temp_std = 12\n",
    "            elif season == 'summer':\n",
    "                temp_mean = 80\n",
    "                temp_std = 10\n",
    "            else:  # fall\n",
    "                temp_mean = 55\n",
    "                temp_std = 15\n",
    "            \n",
    "            # Simulate temperature, precipitation, wind speed, etc.\n",
    "            data = {\n",
    "                'STATION': station_id,\n",
    "                'DATE': date.strftime('%Y-%m-%d'),\n",
    "                'TEMP': round(np.random.normal(temp_mean, temp_std), 1),  # Temperature in F\n",
    "                'PRCP': max(0, round(np.random.exponential(0.1), 2)),  # Precipitation in inches\n",
    "                'WIND': round(np.random.gamma(2, 5), 1),  # Wind speed in mph\n",
    "                'VISIBILITY': min(10, max(0, round(np.random.normal(8, 3), 1))),  # Visibility in miles\n",
    "                'CEILING': round(np.random.normal(20000, 10000)),  # Ceiling height in feet\n",
    "            }\n",
    "            \n",
    "            # Adjust precipitation and visibility based on season\n",
    "            if season == 'winter':\n",
    "                data['PRCP'] *= 1.5  # More precipitation in winter\n",
    "                data['VISIBILITY'] *= 0.8  # Lower visibility in winter\n",
    "            elif season == 'summer':\n",
    "                data['PRCP'] *= 1.2  # More precipitation in summer (thunderstorms)\n",
    "            \n",
    "            all_weather_data.append(data)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    weather_df = pd.DataFrame(all_weather_data)\n",
    "    \n",
    "    # Save raw data\n",
    "    output_file = f\"data/raw/weather/weather_data_{start_date}_to_{end_date}.csv\"\n",
    "    weather_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved synthetic weather data to {output_file}\")\n",
    "    \n",
    "    return weather_df\n",
    "\n",
    "def get_major_airports():\n",
    "    \"\"\"\n",
    "    Get a list of major US airports.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing major airport information\n",
    "    \"\"\"\n",
    "    # List of major US airports with their IATA codes, names, and nearby weather station IDs\n",
    "    major_airports = [\n",
    "        {'IATA': 'ATL', 'Name': 'Hartsfield-Jackson Atlanta International Airport', 'City': 'Atlanta', 'State': 'GA', 'Weather_Station': 'USW00013874'},\n",
    "        {'IATA': 'LAX', 'Name': 'Los Angeles International Airport', 'City': 'Los Angeles', 'State': 'CA', 'Weather_Station': 'USW00023174'},\n",
    "        {'IATA': 'ORD', 'Name': 'O\\'Hare International Airport', 'City': 'Chicago', 'State': 'IL', 'Weather_Station': 'USW00094846'},\n",
    "        {'IATA': 'DFW', 'Name': 'Dallas/Fort Worth International Airport', 'City': 'Dallas', 'State': 'TX', 'Weather_Station': 'USW00003927'},\n",
    "        {'IATA': 'DEN', 'Name': 'Denver International Airport', 'City': 'Denver', 'State': 'CO', 'Weather_Station': 'USW00023062'},\n",
    "        {'IATA': 'JFK', 'Name': 'John F. Kennedy International Airport', 'City': 'New York', 'State': 'NY', 'Weather_Station': 'USW00094789'},\n",
    "        {'IATA': 'SFO', 'Name': 'San Francisco International Airport', 'City': 'San Francisco', 'State': 'CA', 'Weather_Station': 'USW00023234'},\n",
    "        {'IATA': 'SEA', 'Name': 'Seattle-Tacoma International Airport', 'City': 'Seattle', 'State': 'WA', 'Weather_Station': 'USW00024233'},\n",
    "        {'IATA': 'LAS', 'Name': 'Harry Reid International Airport', 'City': 'Las Vegas', 'State': 'NV', 'Weather_Station': 'USW00023169'},\n",
    "        {'IATA': 'MCO', 'Name': 'Orlando International Airport', 'City': 'Orlando', 'State': 'FL', 'Weather_Station': 'USW00012815'},\n",
    "        {'IATA': 'MIA', 'Name': 'Miami International Airport', 'City': 'Miami', 'State': 'FL', 'Weather_Station': 'USW00012839'},\n",
    "        {'IATA': 'CLT', 'Name': 'Charlotte Douglas International Airport', 'City': 'Charlotte', 'State': 'NC', 'Weather_Station': 'USW00013881'},\n",
    "        {'IATA': 'PHX', 'Name': 'Phoenix Sky Harbor International Airport', 'City': 'Phoenix', 'State': 'AZ', 'Weather_Station': 'USW00023183'},\n",
    "        {'IATA': 'IAH', 'Name': 'George Bush Intercontinental Airport', 'City': 'Houston', 'State': 'TX', 'Weather_Station': 'USW00012960'},\n",
    "        {'IATA': 'BOS', 'Name': 'Boston Logan International Airport', 'City': 'Boston', 'State': 'MA', 'Weather_Station': 'USW00014739'}\n",
    "    ]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    airports_df = pd.DataFrame(major_airports)\n",
    "    \n",
    "    # Save to CSV\n",
    "    airports_df.to_csv(\"data/raw/major_airports.csv\", index=False)\n",
    "    print(f\"Saved major airports data to data/raw/major_airports.csv\")\n",
    "    \n",
    "    return airports_df\n",
    "\n",
    "def get_major_airlines():\n",
    "    \"\"\"\n",
    "    Get a list of major US airlines.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing major airline information\n",
    "    \"\"\"\n",
    "    # List of major US airlines with their codes and names\n",
    "    major_airlines = [\n",
    "        {'Code': 'AA', 'Name': 'American Airlines'},\n",
    "        {'Code': 'DL', 'Name': 'Delta Air Lines'},\n",
    "        {'Code': 'UA', 'Name': 'United Airlines'},\n",
    "        {'Code': 'WN', 'Name': 'Southwest Airlines'},\n",
    "        {'Code': 'B6', 'Name': 'JetBlue Airways'},\n",
    "        {'Code': 'AS', 'Name': 'Alaska Airlines'},\n",
    "        {'Code': 'NK', 'Name': 'Spirit Airlines'},\n",
    "        {'Code': 'F9', 'Name': 'Frontier Airlines'},\n",
    "        {'Code': 'G4', 'Name': 'Allegiant Air'},\n",
    "        {'Code': 'HA', 'Name': 'Hawaiian Airlines'}\n",
    "    ]\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    airlines_df = pd.DataFrame(major_airlines)\n",
    "    \n",
    "    # Save to CSV\n",
    "    airlines_df.to_csv(\"data/raw/major_airlines.csv\", index=False)\n",
    "    print(f\"Saved major airlines data to data/raw/major_airlines.csv\")\n",
    "    \n",
    "    return airlines_df\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate data acquisition.\"\"\"\n",
    "    print(\"Starting data acquisition process...\")\n",
    "    \n",
    "    # Get major airports and airlines\n",
    "    airports_df = get_major_airports()\n",
    "    airlines_df = get_major_airlines()\n",
    "    \n",
    "    # Define seasons for recent years\n",
    "    seasons = [\n",
    "        {'name': 'Winter_2023', 'year': 2023, 'months': [1, 2, 12]},\n",
    "        {'name': 'Spring_2023', 'year': 2023, 'months': [3, 4, 5]},\n",
    "        {'name': 'Summer_2023', 'year': 2023, 'months': [6, 7, 8]},\n",
    "        {'name': 'Fall_2023', 'year': 2023, 'months': [9, 10, 11]},\n",
    "        {'name': 'Winter_2024', 'year': 2024, 'months': [1, 2]}\n",
    "    ]\n",
    "    \n",
    "    # Generate synthetic airline data for each season\n",
    "    for season in seasons:\n",
    "        season_name = season['name']\n",
    "        year = season['year']\n",
    "        months = season['months']\n",
    "        \n",
    "        print(f\"\\nProcessing {season_name}...\")\n",
    "        \n",
    "        # Create a directory for this season\n",
    "        os.makedirs(f\"data/raw/airline/{season_name}\", exist_ok=True)\n",
    "        \n",
    "        # Generate data for each month in the season\n",
    "        for month in months:\n",
    "            # Adjust year for December in winter seasons\n",
    "            actual_year = year - 1 if month == 12 and 'Winter' in season_name else year\n",
    "            \n",
    "            # Generate the data\n",
    "            df = generate_synthetic_airline_data(actual_year, month, airports_df, airlines_df)\n",
    "            \n",
    "            # Add a small delay to simulate processing time\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Get weather station IDs from airports DataFrame\n",
    "    weather_stations = airports_df['Weather_Station'].tolist()\n",
    "    \n",
    "    # Generate synthetic weather data for each season\n",
    "    for season in seasons:\n",
    "        season_name = season['name']\n",
    "        year = season['year']\n",
    "        months = season['months']\n",
    "        \n",
    "        # Define date ranges for each season\n",
    "        if 'Winter' in season_name:\n",
    "            if 12 in months:  # Winter spans across years\n",
    "                start_date = f\"{year-1}-12-01\"\n",
    "                end_date = f\"{year}-02-28\"\n",
    "            else:  # Just January and February\n",
    "                start_date = f\"{year}-01-01\"\n",
    "                end_date = f\"{year}-02-28\"\n",
    "        elif 'Spring' in season_name:\n",
    "            start_date = f\"{year}-03-01\"\n",
    "            end_date = f\"{year}-05-31\"\n",
    "        elif 'Summer' in season_name:\n",
    "            start_date = f\"{year}-06-01\"\n",
    "            end_date = f\"{year}-08-31\"\n",
    "        elif 'Fall' in season_name:\n",
    "            start_date = f\"{year}-09-01\"\n",
    "            end_date = f\"{year}-11-30\"\n",
    "        \n",
    "        # Generate weather data\n",
    "        weather_df = generate_synthetic_weather_data(weather_stations, start_date, end_date)\n",
    "    \n",
    "    print(\"\\nData acquisition process completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130114c",
   "metadata": {},
   "source": [
    "### 1.3 Execute Synthetic Data Generation\n",
    "\n",
    "The following cell executes the main data generation process. It will create CSV files in the `data/raw/airline` and `data/raw/weather` directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbc2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    pass\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808e87f",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling and Cleaning\n",
    "\n",
    "This section focuses on loading the raw synthetic data, cleaning it, handling missing values, and performing initial feature engineering to prepare the datasets for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca3f38",
   "metadata": {},
   "source": [
    "### 2.1 Imports for Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4872166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports are already covered in the first code cell, but good to reiterate for section clarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6650a0c",
   "metadata": {},
   "source": [
    "### 2.2 Helper Functions for Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95af5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Wrangling and Cleaning Script for Flight Delay Analysis Project\n",
    "This script processes the synthetic airline and weather data, cleans it,\n",
    "and prepares it for exploratory data analysis and network analysis.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "def load_airline_data():\n",
    "    \"\"\"\n",
    "    Load and combine all airline data files.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Combined DataFrame containing all airline data\n",
    "    \"\"\"\n",
    "    print(\"Loading airline data...\")\n",
    "    \n",
    "    # Get all airline data files\n",
    "    airline_files = glob.glob('data/raw/airline/airline_data_*.csv')\n",
    "    \n",
    "    if not airline_files:\n",
    "        raise FileNotFoundError(\"No airline data files found.\")\n",
    "    \n",
    "    # Load and combine all files\n",
    "    dfs = []\n",
    "    for file in airline_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    print(f\"Loaded {len(combined_df)} flight records from {len(airline_files)} files.\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def load_weather_data():\n",
    "    \"\"\"\n",
    "    Load and combine all weather data files.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Combined DataFrame containing all weather data\n",
    "    \"\"\"\n",
    "    print(\"Loading weather data...\")\n",
    "    \n",
    "    # Get all weather data files\n",
    "    weather_files = glob.glob('data/raw/weather/weather_data_*.csv')\n",
    "    \n",
    "    if not weather_files:\n",
    "        raise FileNotFoundError(\"No weather data files found.\")\n",
    "    \n",
    "    # Load and combine all files\n",
    "    dfs = []\n",
    "    for file in weather_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    print(f\"Loaded {len(combined_df)} weather records from {len(weather_files)} files.\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "def load_airports_data():\n",
    "    \"\"\"\n",
    "    Load airport reference data.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing airport information\n",
    "    \"\"\"\n",
    "    print(\"Loading airport data...\")\n",
    "    \n",
    "    # Load airport data\n",
    "    airports_df = pd.read_csv('data/raw/major_airports.csv')\n",
    "    \n",
    "    print(f\"Loaded information for {len(airports_df)} airports.\")\n",
    "    \n",
    "    return airports_df\n",
    "\n",
    "def load_airlines_data():\n",
    "    \"\"\"\n",
    "    Load airline reference data.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing airline information\n",
    "    \"\"\"\n",
    "    print(\"Loading airline reference data...\")\n",
    "    \n",
    "    # Load airline data\n",
    "    airlines_df = pd.read_csv('data/raw/major_airlines.csv')\n",
    "    \n",
    "    print(f\"Loaded information for {len(airlines_df)} airlines.\")\n",
    "    \n",
    "    return airlines_df\n",
    "\n",
    "def clean_airline_data(df):\n",
    "    \"\"\"\n",
    "    Clean and preprocess airline data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Raw airline data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Cleaned airline data\n",
    "    \"\"\"\n",
    "    print(\"Cleaning airline data...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df_clean['FlightDate'] = pd.to_datetime(df_clean['FlightDate'])\n",
    "    \n",
    "    # Extract year, month, day, day of week\n",
    "    df_clean['Year'] = df_clean['FlightDate'].dt.year\n",
    "    df_clean['Month'] = df_clean['FlightDate'].dt.month\n",
    "    df_clean['Day'] = df_clean['FlightDate'].dt.day\n",
    "    df_clean['DayOfWeek'] = df_clean['FlightDate'].dt.dayofweek + 1  # 1=Monday, 7=Sunday\n",
    "    \n",
    "    # Determine season\n",
    "    season_map = {\n",
    "        1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "        6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall',\n",
    "        11: 'Fall', 12: 'Winter'\n",
    "    }\n",
    "    df_clean['Season'] = df_clean['Month'].map(season_map)\n",
    "    \n",
    "    # Convert scheduled times to proper time format\n",
    "    def format_time(time_str):\n",
    "        if pd.isna(time_str):\n",
    "            return np.nan\n",
    "        time_str = str(int(time_str)).zfill(4)\n",
    "        hour = int(time_str[:-2])\n",
    "        minute = int(time_str[-2:])\n",
    "        return f\"{hour:02d}:{minute:02d}\"\n",
    "    \n",
    "    df_clean['CRSDepTime_Formatted'] = df_clean['CRSDepTime'].apply(format_time)\n",
    "    df_clean['CRSArrTime_Formatted'] = df_clean['CRSArrTime'].apply(format_time)\n",
    "    \n",
    "    # Create a binary delay indicator (1 if arrival delay > 15 minutes)\n",
    "    df_clean['IsDelayed'] = (df_clean['ArrDelay'] > 15).astype(int)\n",
    "    \n",
    "    # Create delay categories\n",
    "    def categorize_delay(minutes):\n",
    "        if pd.isna(minutes) or minutes <= 15:\n",
    "            return 'On Time'\n",
    "        elif minutes <= 30:\n",
    "            return 'Minor Delay'\n",
    "        elif minutes <= 60:\n",
    "            return 'Moderate Delay'\n",
    "        else:\n",
    "            return 'Severe Delay'\n",
    "    \n",
    "    df_clean['DelayCategory'] = df_clean['ArrDelay'].apply(categorize_delay)\n",
    "    \n",
    "    # Fill missing delay cause values with 0\n",
    "    delay_causes = ['CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "    df_clean[delay_causes] = df_clean[delay_causes].fillna(0)\n",
    "    \n",
    "    # Create a total delay minutes column\n",
    "    df_clean['TotalDelayMinutes'] = df_clean[delay_causes].sum(axis=1)\n",
    "    \n",
    "    # Create a primary delay cause column\n",
    "    def get_primary_delay_cause(row):\n",
    "        causes = ['CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "        max_val = 0\n",
    "        max_cause = 'None'\n",
    "        \n",
    "        for cause in causes:\n",
    "            if row[cause] > max_val:\n",
    "                max_val = row[cause]\n",
    "                max_cause = cause.replace('Delay', '')\n",
    "        \n",
    "        return max_cause\n",
    "    \n",
    "    df_clean['PrimaryDelayCause'] = df_clean.apply(get_primary_delay_cause, axis=1)\n",
    "    \n",
    "    print(f\"Airline data cleaned. Shape: {df_clean.shape}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_weather_data(df):\n",
    "    \"\"\"\n",
    "    Clean and preprocess weather data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Raw weather data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Cleaned weather data\n",
    "    \"\"\"\n",
    "    print(\"Cleaning weather data...\")\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df_clean['DATE'] = pd.to_datetime(df_clean['DATE'])\n",
    "    \n",
    "    # Extract year, month, day\n",
    "    df_clean['Year'] = df_clean['DATE'].dt.year\n",
    "    df_clean['Month'] = df_clean['DATE'].dt.month\n",
    "    df_clean['Day'] = df_clean['DATE'].dt.day\n",
    "    \n",
    "    # Determine season\n",
    "    season_map = {\n",
    "        1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "        6: 'Summer', 7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall',\n",
    "        11: 'Fall', 12: 'Winter'\n",
    "    }\n",
    "    df_clean['Season'] = df_clean['Month'].map(season_map)\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_clean['TEMP'] = df_clean['TEMP'].fillna(df_clean['TEMP'].mean())\n",
    "    df_clean['PRCP'] = df_clean['PRCP'].fillna(0)  # Assume no precipitation if missing\n",
    "    df_clean['WIND'] = df_clean['WIND'].fillna(df_clean['WIND'].mean())\n",
    "    df_clean['VISIBILITY'] = df_clean['VISIBILITY'].fillna(df_clean['VISIBILITY'].mean())\n",
    "    df_clean['CEILING'] = df_clean['CEILING'].fillna(df_clean['CEILING'].mean())\n",
    "    \n",
    "    # Create weather condition categories\n",
    "    def categorize_weather(row):\n",
    "        if row['PRCP'] > 0.5:  # Heavy precipitation\n",
    "            return 'Severe'\n",
    "        elif row['PRCP'] > 0.1 or row['VISIBILITY'] < 3 or row['WIND'] > 20:\n",
    "            return 'Moderate'\n",
    "        elif row['PRCP'] > 0 or row['VISIBILITY'] < 7 or row['WIND'] > 10:\n",
    "            return 'Mild'\n",
    "        else:\n",
    "            return 'Clear'\n",
    "    \n",
    "    df_clean['WeatherCondition'] = df_clean.apply(categorize_weather, axis=1)\n",
    "    \n",
    "    print(f\"Weather data cleaned. Shape: {df_clean.shape}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def merge_airport_weather_data(weather_df, airports_df):\n",
    "    \"\"\"\n",
    "    Merge weather data with airport information.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weather_df : pandas.DataFrame\n",
    "        Cleaned weather data\n",
    "    airports_df : pandas.DataFrame\n",
    "        Airport reference data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Weather data with airport information\n",
    "    \"\"\"\n",
    "    print(\"Merging weather data with airport information...\")\n",
    "    \n",
    "    # Create a mapping from weather station to airport code\n",
    "    station_to_airport = dict(zip(airports_df['Weather_Station'], airports_df['IATA']))\n",
    "    \n",
    "    # Add airport code to weather data\n",
    "    weather_df['Airport'] = weather_df['STATION'].map(station_to_airport)\n",
    "    \n",
    "    # Merge with airport information\n",
    "    weather_airport_df = weather_df.merge(\n",
    "        airports_df[['IATA', 'Name', 'City', 'State']],\n",
    "        left_on='Airport',\n",
    "        right_on='IATA',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"Weather data merged with airport information. Shape: {weather_airport_df.shape}\")\n",
    "    \n",
    "    return weather_airport_df\n",
    "\n",
    "def prepare_data_for_network_analysis(airline_df, airports_df):\n",
    "    \"\"\"\n",
    "    Prepare data specifically for network analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    airline_df : pandas.DataFrame\n",
    "        Cleaned airline data\n",
    "    airports_df : pandas.DataFrame\n",
    "        Airport reference data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (airport_network_df, airline_network_df) - DataFrames prepared for network analysis\n",
    "    \"\"\"\n",
    "    print(\"Preparing data for network analysis...\")\n",
    "    \n",
    "    # Create airport-to-airport network data\n",
    "    # Count flights between each airport pair\n",
    "    airport_network = airline_df.groupby(['Origin', 'Dest']).size().reset_index(name='Flights')\n",
    "    \n",
    "    # Add average delay between airport pairs\n",
    "    delay_by_route = airline_df.groupby(['Origin', 'Dest'])['ArrDelay'].mean().reset_index(name='AvgDelay')\n",
    "    airport_network = airport_network.merge(delay_by_route, on=['Origin', 'Dest'])\n",
    "    \n",
    "    # Add distance\n",
    "    distance_by_route = airline_df.groupby(['Origin', 'Dest'])['Distance'].mean().reset_index(name='Distance')\n",
    "    airport_network = airport_network.merge(distance_by_route, on=['Origin', 'Dest'])\n",
    "    \n",
    "    # Create airline route network data\n",
    "    # Count flights by airline and route\n",
    "    airline_network = airline_df.groupby(['Reporting_Airline', 'Origin', 'Dest']).size().reset_index(name='Flights')\n",
    "    \n",
    "    # Add average delay by airline and route\n",
    "    delay_by_airline_route = airline_df.groupby(['Reporting_Airline', 'Origin', 'Dest'])['ArrDelay'].mean().reset_index(name='AvgDelay')\n",
    "    airline_network = airline_network.merge(delay_by_airline_route, on=['Reporting_Airline', 'Origin', 'Dest'])\n",
    "    \n",
    "    # Add distance\n",
    "    airline_network = airline_network.merge(distance_by_route, on=['Origin', 'Dest'])\n",
    "    \n",
    "    print(f\"Network analysis data prepared. Airport network shape: {airport_network.shape}, Airline network shape: {airline_network.shape}\")\n",
    "    \n",
    "    return airport_network, airline_network\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate data wrangling and cleaning.\"\"\"\n",
    "    print(\"Starting data wrangling and cleaning process...\")\n",
    "    \n",
    "    # Create processed data directory if it doesn't exist\n",
    "    os.makedirs('data/processed', exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    airline_df = load_airline_data()\n",
    "    weather_df = load_weather_data()\n",
    "    airports_df = load_airports_data()\n",
    "    airlines_df = load_airlines_data()\n",
    "    \n",
    "    # Clean data\n",
    "    airline_df_clean = clean_airline_data(airline_df)\n",
    "    weather_df_clean = clean_weather_data(weather_df)\n",
    "    \n",
    "    # Merge weather data with airport information\n",
    "    weather_airport_df = merge_airport_weather_data(weather_df_clean, airports_df)\n",
    "    \n",
    "    # Prepare data for network analysis\n",
    "    airport_network_df, airline_network_df = prepare_data_for_network_analysis(airline_df_clean, airports_df)\n",
    "    \n",
    "    # Save processed data\n",
    "    airline_df_clean.to_csv('data/processed/airline_data_clean.csv', index=False)\n",
    "    weather_airport_df.to_csv('data/processed/weather_data_clean.csv', index=False)\n",
    "    airport_network_df.to_csv('data/processed/airport_network.csv', index=False)\n",
    "    airline_network_df.to_csv('data/processed/airline_network.csv', index=False)\n",
    "    \n",
    "    print(\"Data wrangling and cleaning process completed.\")\n",
    "    print(f\"Saved processed airline data to data/processed/airline_data_clean.csv\")\n",
    "    print(f\"Saved processed weather data to data/processed/weather_data_clean.csv\")\n",
    "    print(f\"Saved airport network data to data/processed/airport_network.csv\")\n",
    "    print(f\"Saved airline network data to data/processed/airline_network.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635f794",
   "metadata": {},
   "source": [
    "### 2.3 Execute Data Wrangling\n",
    "\n",
    "This cell runs the data wrangling pipeline. It loads the raw data generated in the previous step, cleans it, and saves the processed files to the `data/processed` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40de4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    pass\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289617f6",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we perform EDA on the cleaned and processed data. This involves creating various visualizations to understand distributions, relationships, seasonal patterns, and network characteristics related to flight delays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461b2e1",
   "metadata": {},
   "source": [
    "### 3.1 Imports for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import networkx as nx\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79619f1d",
   "metadata": {},
   "source": [
    "### 3.2 Helper Functions for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exploratory Data Analysis (EDA) Script for Flight Delay Analysis Project\n",
    "This script performs exploratory data analysis on the processed airline and weather data,\n",
    "creating visualizations to understand patterns and relationships in the data.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Create directories for visualizations\n",
    "os.makedirs('visualizations/general', exist_ok=True)\n",
    "os.makedirs('visualizations/seasonal', exist_ok=True)\n",
    "os.makedirs('visualizations/network', exist_ok=True)\n",
    "\n",
    "def load_processed_data():\n",
    "    \"\"\"\n",
    "    Load all processed data files.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (airline_df, weather_df, airport_network_df, airline_network_df, airports_df, airlines_df)\n",
    "    \"\"\"\n",
    "    print(\"Loading processed data...\")\n",
    "    \n",
    "    # Load processed data\n",
    "    airline_df = pd.read_csv('data/processed/airline_data_clean.csv')\n",
    "    weather_df = pd.read_csv('data/processed/weather_data_clean.csv')\n",
    "    airport_network_df = pd.read_csv('data/processed/airport_network.csv')\n",
    "    airline_network_df = pd.read_csv('data/processed/airline_network.csv')\n",
    "    \n",
    "    # Load reference data\n",
    "    airports_df = pd.read_csv('data/raw/major_airports.csv')\n",
    "    airlines_df = pd.read_csv('data/raw/major_airlines.csv')\n",
    "    \n",
    "    # Convert dates to datetime\n",
    "    airline_df['FlightDate'] = pd.to_datetime(airline_df['FlightDate'])\n",
    "    weather_df['DATE'] = pd.to_datetime(weather_df['DATE'])\n",
    "    \n",
    "    print(\"Data loaded successfully.\")\n",
    "    \n",
    "    return airline_df, weather_df, airport_network_df, airline_network_df, airports_df, airlines_df\n",
    "\n",
    "def general_statistics(airline_df, weather_df):\n",
    "    \"\"\"\n",
    "    Generate general statistics and visualizations about the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    airline_df : pandas.DataFrame\n",
    "        Processed airline data\n",
    "    weather_df : pandas.DataFrame\n",
    "        Processed weather data\n",
    "    \"\"\"\n",
    "    print(\"Generating general statistics and visualizations...\")\n",
    "    \n",
    "    # Summary statistics for airline data\n",
    "    airline_stats = airline_df.describe(include='all')\n",
    "    airline_stats.to_csv('results/airline_summary_statistics.csv')\n",
    "    \n",
    "    # Summary statistics for weather data\n",
    "    weather_stats = weather_df.describe(include='all')\n",
    "    weather_stats.to_csv('results/weather_summary_statistics.csv')\n",
    "    \n",
    "    # Flight counts by airline\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    airline_counts = airline_df['Reporting_Airline'].value_counts()\n",
    "    sns.barplot(x=airline_counts.index, y=airline_counts.values)\n",
    "    plt.title('Number of Flights by Airline', fontsize=16)\n",
    "    plt.xlabel('Airline', fontsize=14)\n",
    "    plt.ylabel('Number of Flights', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/general/flights_by_airline.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Flight counts by airport (origin)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    origin_counts = airline_df['Origin'].value_counts()\n",
    "    sns.barplot(x=origin_counts.index, y=origin_counts.values)\n",
    "    plt.title('Number of Departing Flights by Airport', fontsize=16)\n",
    "    plt.xlabel('Airport', fontsize=14)\n",
    "    plt.ylabel('Number of Flights', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/general/flights_by_origin.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Delay distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(airline_df['ArrDelay'].dropna(), bins=50, kde=True)\n",
    "    plt.title('Distribution of Arrival Delays', fontsize=16)\n",
    "    plt.xlabel('Arrival Delay (minutes)', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.axvline(x=15, color='red', linestyle='--', label='15-minute threshold')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/general/delay_distribution.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Delay categories\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    delay_cats = airline_df['DelayCategory'].value_counts()\n",
    "    sns.barplot(x=delay_cats.index, y=delay_cats.values)\n",
    "    plt.title('Flight Delay Categories', fontsize=16)\n",
    "    plt.xlabel('Delay Category', fontsize=14)\n",
    "    plt.ylabel('Number of Flights', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/general/delay_categories.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Primary delay causes\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    delay_causes = airline_df['PrimaryDelayCause'].value_counts()\n",
    "    sns.barplot(x=delay_causes.index, y=delay_causes.values)\n",
    "    plt.title('Primary Causes of Delay', fontsize=16)\n",
    "    plt.xlabel('Delay Cause', fontsize=14)\n",
    "    plt.ylabel('Number of Flights', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/general/delay_causes.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Weather condition distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    weather_conds = weather_df['WeatherCondition'].value_counts()\n",
    "    sns.barplot(x=weather_conds.index, y=weather_conds.values)\n",
    "    plt.title('Distribution of Weather Conditions', fontsize=16)\n",
    "    plt.xlabel('Weather Condition', fontsize=14)\n",
    "    plt.ylabel('Number of Days', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/general/weather_conditions.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"General statistics and visualizations generated.\")\n",
    "\n",
    "def seasonal_analysis(airline_df, weather_df):\n",
    "    \"\"\"\n",
    "    Perform seasonal analysis with visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    airline_df : pandas.DataFrame\n",
    "        Processed airline data\n",
    "    weather_df : pandas.DataFrame\n",
    "        Processed weather data\n",
    "    \"\"\"\n",
    "    print(\"Performing seasonal analysis...\")\n",
    "    \n",
    "    # Average delay by season\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    season_delay = airline_df.groupby('Season')['ArrDelay'].mean().reindex(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    sns.barplot(x=season_delay.index, y=season_delay.values)\n",
    "    plt.title('Average Arrival Delay by Season', fontsize=16)\n",
    "    plt.xlabel('Season', fontsize=14)\n",
    "    plt.ylabel('Average Delay (minutes)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/seasonal/avg_delay_by_season.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Delay categories by season\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    season_delay_cat = pd.crosstab(airline_df['Season'], airline_df['DelayCategory'])\n",
    "    season_delay_cat = season_delay_cat.reindex(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    season_delay_cat.plot(kind='bar', stacked=True)\n",
    "    plt.title('Delay Categories by Season', fontsize=16)\n",
    "    plt.xlabel('Season', fontsize=14)\n",
    "    plt.ylabel('Number of Flights', fontsize=14)\n",
    "    plt.legend(title='Delay Category')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/seasonal/delay_categories_by_season.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Primary delay causes by season\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    season_cause = pd.crosstab(airline_df['Season'], airline_df['PrimaryDelayCause'])\n",
    "    season_cause = season_cause.reindex(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    season_cause.plot(kind='bar', stacked=True)\n",
    "    plt.title('Primary Delay Causes by Season', fontsize=16)\n",
    "    plt.xlabel('Season', fontsize=14)\n",
    "    plt.ylabel('Number of Flights', fontsize=14)\n",
    "    plt.legend(title='Delay Cause')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/seasonal/delay_causes_by_season.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Weather conditions by season\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    weather_season = pd.crosstab(weather_df['Season'], weather_df['WeatherCondition'])\n",
    "    weather_season = weather_season.reindex(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    weather_season.plot(kind='bar', stacked=True)\n",
    "    plt.title('Weather Conditions by Season', fontsize=16)\n",
    "    plt.xlabel('Season', fontsize=14)\n",
    "    plt.ylabel('Number of Days', fontsize=14)\n",
    "    plt.legend(title='Weather Condition')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/seasonal/weather_by_season.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Average temperature by season\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    season_temp = weather_df.groupby('Season')['TEMP'].mean().reindex(['Winter', 'Spring', 'Summer', 'Fall'])\n",
    "    sns.barplot(x=season_temp.index, y=season_temp.values)\n",
    "    plt.title('Average Temperature by Season', fontsize=16)\n",
    "    plt.xlabel('Season', fontsize=14)\n",
    "    plt.ylabel('Average Temperature (F)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/seasonal/avg_temp_by_season.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Heatmap of average delay by month and day of week\n",
    "    monthly_dow_delay = airline_df.pivot_table(\n",
    "        values='ArrDelay', \n",
    "        index='DayOfWeek', \n",
    "        columns='Month', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(monthly_dow_delay, cmap='YlOrRd', annot=True, fmt='.1f')\n",
    "    plt.title('Average Arrival Delay by Month and Day of Week', fontsize=16)\n",
    "    plt.xlabel('Month', fontsize=14)\n",
    "    plt.ylabel('Day of Week (1=Monday, 7=Sunday)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/seasonal/delay_heatmap_month_dow.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Seasonal analysis completed.\")\n",
    "\n",
    "def network_analysis_visualization(airport_network_df, airline_network_df, airports_df, airlines_df):\n",
    "    \"\"\"\n",
    "    Perform initial network analysis and visualizations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    airport_network_df : pandas.DataFrame\n",
    "        Airport network data\n",
    "    airline_network_df : pandas.DataFrame\n",
    "        Airline network data\n",
    "    airports_df : pandas.DataFrame\n",
    "        Airport reference data\n",
    "    airlines_df : pandas.DataFrame\n",
    "        Airline reference data\n",
    "    \"\"\"\n",
    "    print(\"Performing network analysis and visualizations...\")\n",
    "    \n",
    "    # Create a graph for airport network\n",
    "    G_airport = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes (airports)\n",
    "    for _, airport in airports_df.iterrows():\n",
    "        G_airport.add_node(airport['IATA'], name=airport['Name'], city=airport['City'], state=airport['State'])\n",
    "    \n",
    "    # Add edges (routes)\n",
    "    for _, route in airport_network_df.iterrows():\n",
    "        G_airport.add_edge(\n",
    "            route['Origin'], \n",
    "            route['Dest'], \n",
    "            weight=route['Flights'],\n",
    "            delay=route['AvgDelay'],\n",
    "            distance=route['Distance']\n",
    "        )\n",
    "    \n",
    "    # Calculate network metrics for airports\n",
    "    airport_metrics = {\n",
    "        'Airport': [],\n",
    "        'Degree': [],\n",
    "        'In_Degree': [],\n",
    "        'Out_Degree': [],\n",
    "        'Betweenness': [],\n",
    "        'Eigenvector': []\n",
    "    }\n",
    "    \n",
    "    betweenness = nx.betweenness_centrality(G_airport, weight='weight')\n",
    "    eigenvector = nx.eigenvector_centrality(G_airport, weight='weight', max_iter=1000)\n",
    "    \n",
    "    for node in G_airport.nodes():\n",
    "        airport_metrics['Airport'].append(node)\n",
    "        airport_metrics['Degree'].append(G_airport.degree(node, weight='weight'))\n",
    "        airport_metrics['In_Degree'].append(G_airport.in_degree(node, weight='weight'))\n",
    "        airport_metrics['Out_Degree'].append(G_airport.out_degree(node, weight='weight'))\n",
    "        airport_metrics['Betweenness'].append(betweenness[node])\n",
    "        airport_metrics['Eigenvector'].append(eigenvector[node])\n",
    "    \n",
    "    airport_metrics_df = pd.DataFrame(airport_metrics)\n",
    "    airport_metrics_df = airport_metrics_df.sort_values('Degree', ascending=False)\n",
    "    airport_metrics_df.to_csv('results/airport_network_metrics.csv', index=False)\n",
    "    \n",
    "    # Visualize airport network\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    pos = nx.spring_layout(G_airport, seed=42)\n",
    "    \n",
    "    # Draw nodes with size based on degree\n",
    "    node_sizes = [G_airport.degree(node, weight='weight') * 10 for node in G_airport.nodes()]\n",
    "    nx.draw_networkx_nodes(G_airport, pos, node_size=node_sizes, node_color='skyblue', alpha=0.8)\n",
    "    \n",
    "    # Draw edges with width based on number of flights\n",
    "    edge_weights = [G_airport[u][v]['weight'] / 50 for u, v in G_airport.edges()]\n",
    "    nx.draw_networkx_edges(G_airport, pos, width=edge_weights, alpha=0.5, edge_color='gray', arrows=True, arrowsize=10)\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G_airport, pos, font_size=10, font_family='sans-serif')\n",
    "    \n",
    "    plt.title('Airport Network: Connections Between Major Airports', fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/network/airport_network.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a bar chart of airport centrality metrics\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Airport', y='Degree', data=airport_metrics_df)\n",
    "    plt.title('Airport Network: Total Degree Centrality', fontsize=16)\n",
    "    plt.xlabel('Airport', fontsize=14)\n",
    "    plt.ylabel('Degree (weighted by flights)', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/network/airport_degree_centrality.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a bar chart of betweenness centrality\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    betweenness_df = airport_metrics_df.sort_values('Betweenness', ascending=False)\n",
    "    sns.barplot(x='Airport', y='Betweenness', data=betweenness_df)\n",
    "    plt.title('Airport Network: Betweenness Centrality', fontsize=16)\n",
    "    plt.xlabel('Airport', fontsize=14)\n",
    "    plt.ylabel('Betweenness Centrality', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('visualizations/network/airport_betweenness_centrality.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Analyze airline networks\n",
    "    # Get top 3 airlines by number of flights\n",
    "    top_airlines = airline_network_df.groupby('Reporting_Airline')['Flights'].sum().nlargest(3).index.tolist()\n",
    "    \n",
    "    for airline_code in top_airlines:\n",
    "        airline_name = airlines_df[airlines_df['Code'] == airline_code]['Name'].values[0]\n",
    "        \n",
    "        # Filter network data for this airline\n",
    "        airline_routes = airline_network_df[airline_network_df['Reporting_Airline'] == airline_code]\n",
    "        \n",
    "        # Create a graph for this airline's network\n",
    "        G_airline = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes (airports)\n",
    "        for _, airport in airports_df.iterrows():\n",
    "            G_airline.add_node(airport['IATA'], name=airport['Name'], city=airport['City'], state=airport['State'])\n",
    "        \n",
    "        # Add edges (routes)\n",
    "        for _, route in airline_routes.iterrows():\n",
    "            G_airline.add_edge(\n",
    "                route['Origin'], \n",
    "                route['Dest'], \n",
    "                weight=route['Flights'],\n",
    "                delay=route['AvgDelay'],\n",
    "                distance=route['Distance']\n",
    "            )\n",
    "        \n",
    "        # Visualize airline network\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        pos = nx.spring_layout(G_airline, seed=42)\n",
    "        \n",
    "        # Draw nodes with size based on degree\n",
    "        node_sizes = [G_airline.degree(node, weight='weight') * 20 for node in G_airline.nodes()]\n",
    "        nx.draw_networkx_nodes(G_airline, pos, node_size=node_sizes, node_color='lightgreen', alpha=0.8)\n",
    "        \n",
    "        # Draw edges with width based on number of flights\n",
    "        edge_weights = [G_airline[u][v]['weight'] / 10 for u, v in G_airline.edges()]\n",
    "        nx.draw_networkx_edges(G_airline, pos, width=edge_weights, alpha=0.5, edge_color='gray', arrows=True, arrowsize=10)\n",
    "        \n",
    "        # Draw labels\n",
    "        nx.draw_networkx_labels(G_airline, pos, font_size=10, font_family='sans-serif')\n",
    "        \n",
    "        plt.title(f'{airline_name} ({airline_code}) Network', fontsize=16)\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'visualizations/network/airline_network_{airline_code}.png', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"Network analysis and visualizations completed.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate exploratory data analysis.\"\"\"\n",
    "    print(\"Starting exploratory data analysis...\")\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    # Load processed data\n",
    "    airline_df, weather_df, airport_network_df, airline_network_df, airports_df, airlines_df = load_processed_data()\n",
    "    \n",
    "    # Generate general statistics and visualizations\n",
    "    general_statistics(airline_df, weather_df)\n",
    "    \n",
    "    # Perform seasonal analysis\n",
    "    seasonal_analysis(airline_df, weather_df)\n",
    "    \n",
    "    # Perform network analysis and visualizations\n",
    "    network_analysis_visualization(airport_network_df, airline_network_df, airports_df, airlines_df)\n",
    "    \n",
    "    print(\"Exploratory data analysis completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6095e",
   "metadata": {},
   "source": [
    "### 3.3 Execute Exploratory Data Analysis\n",
    "\n",
    "The following cell runs the EDA pipeline. It loads the processed data and generates various plots and summary statistics, saving visualizations to the `visualizations` directory and results to the `results` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    pass\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38a5c0",
   "metadata": {},
   "source": [
    "## End of Notebook\n",
    "\n",
    "This notebook has demonstrated the end-to-end workflow for flight delay analysis, starting from synthetic data generation, proceeding through data wrangling and cleaning, and concluding with exploratory data analysis. The generated data, processed files, and visualizations are saved in their respective directories."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
